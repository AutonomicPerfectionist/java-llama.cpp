package de.kherud.llama.foreign;

import java.nio.ByteBuffer;
import java.nio.FloatBuffer;
import java.nio.IntBuffer;

import com.sun.jna.Callback;
import com.sun.jna.Library;
import com.sun.jna.Native;
import com.sun.jna.NativeLibrary;
import com.sun.jna.Pointer;
import com.sun.jna.PointerType;
import com.sun.jna.ptr.FloatByReference;
import com.sun.jna.ptr.PointerByReference;

/**
 * JNA Wrapper for library <b>llama</b><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> , <a href="http://rococoa.dev.java.net/">Rococoa</a>, or <a href="http://jna.dev.java.net/">JNA</a>.
 */
public class LlamaLibrary implements Library {
	public static final String JNA_LIBRARY_NAME = "llama";
	public static final NativeLibrary JNA_NATIVE_LIB = NativeLibrary.getInstance(LlamaLibrary.JNA_LIBRARY_NAME);
	static {
		Native.register(LlamaLibrary.class, LlamaLibrary.JNA_NATIVE_LIB);
	}
	public interface llama_log_level {
		int LLAMA_LOG_LEVEL_ERROR = 2;
		int LLAMA_LOG_LEVEL_WARN = 3;
		int LLAMA_LOG_LEVEL_INFO = 4;
	}
	public interface llama_ftype {
		int LLAMA_FTYPE_ALL_F32 = 0;
		int LLAMA_FTYPE_MOSTLY_F16 = 1;
		int LLAMA_FTYPE_MOSTLY_Q4_0 = 2;
		int LLAMA_FTYPE_MOSTLY_Q4_1 = 3;
		int LLAMA_FTYPE_MOSTLY_Q4_1_SOME_F16 = 4;
		int LLAMA_FTYPE_MOSTLY_Q8_0 = 7;
		int LLAMA_FTYPE_MOSTLY_Q5_0 = 8;
		int LLAMA_FTYPE_MOSTLY_Q5_1 = 9;
		int LLAMA_FTYPE_MOSTLY_Q2_K = 10;
		int LLAMA_FTYPE_MOSTLY_Q3_K_S = 11;
		int LLAMA_FTYPE_MOSTLY_Q3_K_M = 12;
		int LLAMA_FTYPE_MOSTLY_Q3_K_L = 13;
		int LLAMA_FTYPE_MOSTLY_Q4_K_S = 14;
		int LLAMA_FTYPE_MOSTLY_Q4_K_M = 15;
		int LLAMA_FTYPE_MOSTLY_Q5_K_S = 16;
		int LLAMA_FTYPE_MOSTLY_Q5_K_M = 17;
		int LLAMA_FTYPE_MOSTLY_Q6_K = 18;
	}
	public interface llama_gretype {
		int LLAMA_GRETYPE_END = 0;
		int LLAMA_GRETYPE_ALT = 1;
		int LLAMA_GRETYPE_RULE_REF = 2;
		int LLAMA_GRETYPE_CHAR = 3;
		int LLAMA_GRETYPE_CHAR_NOT = 4;
		int LLAMA_GRETYPE_CHAR_RNG_UPPER = 5;
		int LLAMA_GRETYPE_CHAR_ALT = 6;
	}
	public static final int LLAMA_MAX_DEVICES = 1;
	public static final int LLAMA_FILE_MAGIC_GGJT = 0x67676a74;
	public static final int LLAMA_FILE_MAGIC_GGLA = 0x67676c61;
	public static final int LLAMA_FILE_MAGIC_GGMF = 0x67676d66;
	public static final int LLAMA_FILE_MAGIC_GGML = 0x67676d6c;
	public static final int LLAMA_FILE_MAGIC_GGSN = 0x6767736e;
	public static final int LLAMA_FILE_VERSION = 3;
	public static final int LLAMA_FILE_MAGIC = 0x67676a74;
	public static final int LLAMA_FILE_MAGIC_UNVERSIONED = 0x67676d6c;
	public static final int LLAMA_SESSION_MAGIC = 0x6767736e;
	public static final int LLAMA_SESSION_VERSION = 1;
	public static final long LLAMA_DEFAULT_SEED = 0xFFFFFFFFL;
	public static final float LLAMA_DEFAULT_RMS_EPS = 5e-6f;
	public interface llama_progress_callback extends Callback {
		void apply(float progress, Pointer ctx);
	}
	public interface llama_log_callback extends Callback {
		void apply(int level, Pointer text, Pointer user_data);
	}
	public static native void llama_log_set(LlamaLibrary.llama_log_callback log_callback, Pointer user_data);
	public static native int llama_max_devices();
	public static native de.kherud.llama.foreign.llama_context_params.ByValue llama_context_default_params();
	public static native llama_model_quantize_params.ByValue llama_model_quantize_default_params();
	public static native byte llama_mmap_supported();
	public static native byte llama_mlock_supported();
	public static native void llama_backend_init(byte numa);
	public static native void llama_backend_free();
	public static native long llama_time_us();
	public static native LlamaLibrary.llama_model llama_load_model_from_file(String path_model, de.kherud.llama.foreign.llama_context_params.ByValue params);
	public static native void llama_free_model(LlamaLibrary.llama_model model);
	public static native LlamaLibrary.llama_context llama_new_context_with_model(LlamaLibrary.llama_model model, de.kherud.llama.foreign.llama_context_params.ByValue params);
	public static native LlamaLibrary.llama_context llama_init_from_file(String path_model, de.kherud.llama.foreign.llama_context_params.ByValue params);
	public static native void llama_free(LlamaLibrary.llama_context ctx);
	public static native int llama_model_quantize(String fname_inp, String fname_out, llama_model_quantize_params params);
	public static native int llama_apply_lora_from_file(LlamaLibrary.llama_context ctx, String path_lora, String path_base_model, int n_threads);
	public static native int llama_model_apply_lora_from_file(LlamaLibrary.llama_model model, String path_lora, String path_base_model, int n_threads);
	public static native int llama_get_kv_cache_token_count(LlamaLibrary.llama_context ctx);
	public static native void llama_set_rng_seed(LlamaLibrary.llama_context ctx, int seed);
	public static native NativeSize llama_get_state_size(LlamaLibrary.llama_context ctx);
	public static native NativeSize llama_copy_state_data(LlamaLibrary.llama_context ctx, ByteBuffer dst);
	public static native NativeSize llama_set_state_data(LlamaLibrary.llama_context ctx, ByteBuffer src);
	public static native byte llama_load_session_file(LlamaLibrary.llama_context ctx, String path_session, IntBuffer tokens_out, NativeSize n_token_capacity, NativeSizeByReference n_token_count_out);
	public static native byte llama_save_session_file(LlamaLibrary.llama_context ctx, String path_session, IntBuffer tokens, NativeSize n_token_count);
	public static native int llama_eval(LlamaLibrary.llama_context ctx, IntBuffer tokens, int n_tokens, int n_past, int n_threads);
	public static native int llama_eval_embd(LlamaLibrary.llama_context ctx, float[] embd, int n_tokens, int n_past, int n_threads);
	public static native int llama_eval_export(LlamaLibrary.llama_context ctx, String fname);
	public static native int llama_tokenize(LlamaLibrary.llama_context ctx, String text, IntBuffer tokens, int n_max_tokens, byte add_bos);
	public static native int llama_tokenize_with_model(LlamaLibrary.llama_model model, String text, IntBuffer tokens, int n_max_tokens, byte add_bos);
	public static native int llama_n_vocab(LlamaLibrary.llama_context ctx);
	public static native int llama_n_ctx(LlamaLibrary.llama_context ctx);
	public static native int llama_n_embd(LlamaLibrary.llama_context ctx);
	public static native int llama_n_vocab_from_model(LlamaLibrary.llama_model model);
	public static native int llama_n_ctx_from_model(LlamaLibrary.llama_model model);
	public static native int llama_n_embd_from_model(LlamaLibrary.llama_model model);
	public static native int llama_get_vocab(LlamaLibrary.llama_context ctx, PointerByReference strings, FloatBuffer scores, int capacity);
	public static native int llama_get_vocab_from_model(LlamaLibrary.llama_model model, PointerByReference strings, FloatBuffer scores, int capacity);
	public static native FloatByReference llama_get_logits(LlamaLibrary.llama_context ctx);
	public static native FloatByReference llama_get_embeddings(LlamaLibrary.llama_context ctx);
	public static native String llama_token_to_str(LlamaLibrary.llama_context ctx, int token);
	public static native String llama_token_to_str_with_model(LlamaLibrary.llama_model model, int token);
	public static native int llama_token_bos();
	public static native int llama_token_eos();
	public static native int llama_token_nl();
	public static native LlamaLibrary.llama_grammar llama_grammar_init(PointerByReference rules, NativeSize n_rules, NativeSize start_rule_index);
	public static native void llama_grammar_free(LlamaLibrary.llama_grammar grammar);
	public static native void llama_sample_repetition_penalty(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, IntBuffer last_tokens, NativeSize last_tokens_size, float penalty);
	public static native void llama_sample_frequency_and_presence_penalties(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, IntBuffer last_tokens, NativeSize last_tokens_size, float alpha_frequency, float alpha_presence);
	public static native void llama_sample_classifier_free_guidance(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, LlamaLibrary.llama_context guidance_ctx, float scale);
	public static native void llama_sample_softmax(LlamaLibrary.llama_context ctx, llama_token_data_array candidates);
	public static native void llama_sample_top_k(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, int k, NativeSize min_keep);
	public static native void llama_sample_top_p(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, float p, NativeSize min_keep);
	public static native void llama_sample_tail_free(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, float z, NativeSize min_keep);
	public static native void llama_sample_typical(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, float p, NativeSize min_keep);
	public static native void llama_sample_temperature(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, float temp);
	public static native void llama_sample_grammar(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, LlamaLibrary.llama_grammar grammar);
	public static native int llama_sample_token_mirostat(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, float tau, float eta, int m, FloatBuffer mu);
	public static native int llama_sample_token_mirostat_v2(LlamaLibrary.llama_context ctx, llama_token_data_array candidates, float tau, float eta, FloatBuffer mu);
	public static native int llama_sample_token_greedy(LlamaLibrary.llama_context ctx, llama_token_data_array candidates);
	public static native int llama_sample_token(LlamaLibrary.llama_context ctx, llama_token_data_array candidates);
	public static native void llama_grammar_accept_token(LlamaLibrary.llama_context ctx, LlamaLibrary.llama_grammar grammar, int token);
	public static native de.kherud.llama.foreign.llama_timings.ByValue llama_get_timings(LlamaLibrary.llama_context ctx);
	public static native void llama_print_timings(LlamaLibrary.llama_context ctx);
	public static native void llama_reset_timings(LlamaLibrary.llama_context ctx);
	public static native String llama_print_system_info();
	/** Pointer to unknown (opaque) type */
	public static class llama_grammar extends PointerType {
		public llama_grammar(Pointer address) {
			super(address);
		}
		public llama_grammar() {
			super();
		}
	}
	/** Pointer to unknown (opaque) type */
	public static class llama_model extends PointerType {
		public llama_model(Pointer address) {
			super(address);
		}
		public llama_model() {
			super();
		}
	}
	/** Pointer to unknown (opaque) type */
	public static class llama_context extends PointerType {
		public llama_context(Pointer address) {
			super(address);
		}

		public llama_context() {
			super();
		}
	}
}
