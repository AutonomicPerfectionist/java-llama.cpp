package de.kherud.llama.foreign;
import com.sun.jna.Pointer;
import com.sun.jna.Structure;
import java.util.Arrays;
import java.util.List;
/**
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> , <a href="http://rococoa.dev.java.net/">Rococoa</a>, or <a href="http://jna.dev.java.net/">JNA</a>.
 */
public class llama_model_quantize_params extends Structure {
	/** number of threads to use for quantizing, if less than 0 will use std::thread::hardware_concurrency() */
	public int nthread;
	public int getNthread() {
		return nthread;
	}
	public void setNthread(int nthread) {
		this.nthread = nthread;
	}
	/**
	 * @see LlamaLibrary.llama_ftype
	 * quantize to this llama_ftype
	 */
	public int ftype;
	public int getFtype() {
		return ftype;
	}
	public void setFtype(int ftype) {
		this.ftype = ftype;
	}
	/** allow quantizing non-f32/f16 tensors */
	public byte allow_requantize;
	public byte getAllow_requantize() {
		return allow_requantize;
	}
	public void setAllow_requantize(byte allow_requantize) {
		this.allow_requantize = allow_requantize;
	}
	/** quantize output.weight */
	public byte quantize_output_tensor;
	public byte getQuantize_output_tensor() {
		return quantize_output_tensor;
	}
	public void setQuantize_output_tensor(byte quantize_output_tensor) {
		this.quantize_output_tensor = quantize_output_tensor;
	}
	public llama_model_quantize_params() {
		super();
	}
	@Override
	protected List<String> getFieldOrder() {
		return Arrays.asList("nthread", "ftype", "allow_requantize", "quantize_output_tensor");
	}
	public llama_model_quantize_params(int nthread, int ftype, byte allow_requantize, byte quantize_output_tensor) {
		super();
		this.nthread = nthread;
		this.ftype = ftype;
		this.allow_requantize = allow_requantize;
		this.quantize_output_tensor = quantize_output_tensor;
	}
	public llama_model_quantize_params(Pointer peer) {
		super(peer);
	}
	public static class ByReference extends llama_model_quantize_params implements Structure.ByReference {
		
	};
	public static class ByValue extends llama_model_quantize_params implements Structure.ByValue {
		
	};
}
